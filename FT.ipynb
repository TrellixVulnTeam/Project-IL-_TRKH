{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Finale_Cat_forgetting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armando-larocca/Project-IL-/blob/master/FT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwLLPH7WNg6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch.optim as optim \n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "DEVICE = 'cuda' \n",
        "\n",
        "NUM_CLASSES = 100 \n",
        "\n",
        "batch_size = 128    \n",
        "LR = 0.2      \n",
        "MOMENTUM = 0.9       \n",
        "WEIGHT_DECAY = 1e-5  \n",
        "\n",
        "NUM_EPOCHS = 70  \n",
        "STEP_SIZE = [49,63]  \n",
        "GAMMA = 0.2       \n",
        "LOG_FREQUENCY = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2byub6dTNpXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isdir('./Project-dir'):\n",
        "  !git clone https://github.com/armando-larocca/Project-IL-\n",
        "\n",
        "if not os.path.isdir('content/cifar100.py'):\n",
        "  !mv '/content/Project-IL-/cifar100.py' '/content'  \n",
        "  !mv '/content/Project-IL-/utils.py' '/content'  \n",
        "\n",
        "from cifar100 import * "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olQRwr3eNsL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5071, 0.4867, 0.4408),std=(0.2675, 0.2565, 0.2761)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5071, 0.4867, 0.4408),std=(0.2675, 0.2565, 0.2761)),\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wmw7KinNv58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "shf = []\n",
        "for x in range(0,100):\n",
        "  shf.append(x)\n",
        "\n",
        "random.shuffle(shf)\n",
        "\n",
        "train_dataset = Cifar100(\".\\Data\", train=True, transform=transform)\n",
        "test_dataset = Cifar100(\".\\Data\", train=False, transform=transform_test)\n",
        "\n",
        "train_dataset._shuffle_(shf)\n",
        "test_dataset._shuffle_(shf)\n",
        "\n",
        "incr_train = train_dataset.__incremental_train_indexes__(1)\n",
        "incr_val = test_dataset.__incremental_val_indexes__(0)\n",
        "\n",
        "decine_train = []\n",
        "decine_val = []\n",
        "\n",
        "for i in range(0,10):\n",
        "  val_dataset = Subset(test_dataset, incr_val[i])\n",
        "  training_dataset = Subset(train_dataset, incr_train[i])\n",
        "  decine_train.append(training_dataset)\n",
        "  decine_val.append(val_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg-_UimmNzuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isdir('content/cifarResnet.py'):\n",
        "  !mv '/content/Project-IL-/cifarResnet.py' '/content'\n",
        "\n",
        "from cifarResnet import resnet32\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vCFeETCnx1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FT(nn.Module):\n",
        "    def __init__(self,  n_classes):\n",
        "        \n",
        "        #### Network architecture #### \n",
        "        super(FT, self).__init__()\n",
        "        self.feature_extractor = resnet32()\n",
        "        self.fc = nn.Linear(64, n_classes, bias=True)\n",
        "\n",
        "        self.n_classes = n_classes\n",
        "        self.n_known = 0\n",
        "       \n",
        "        self.p = self.parameters()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def increment_classes(self, n):\n",
        "      in_features = self.fc.in_features\n",
        "      out_features = self.fc.out_features\n",
        "      weight = self.fc.weight.data\n",
        "      bias = self.fc.bias.data\n",
        "\n",
        "      self.fc = nn.Linear(in_features, out_features+n, bias=True)\n",
        "      self.fc.weight.data[:out_features] = weight\n",
        "      self.fc.bias.data[:out_features] = bias\n",
        "      self.n_classes += n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHf8KLZ0zWu1",
        "colab_type": "text"
      },
      "source": [
        "**Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX0RvavFRP28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_acc = []\n",
        "tot_matrix = []\n",
        "tot_labe = []\n",
        "\n",
        "net = FT(10)\n",
        "\n",
        "for s in range(0,10):\n",
        "\n",
        "  net.cuda()\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(decine_train[int(s)], batch_size=batch_size,shuffle=True, num_workers=4)\n",
        "  test_loader = torch.utils.data.DataLoader(decine_val[int(s)], batch_size=batch_size,shuffle=True, num_workers=4)\n",
        "\n",
        "\n",
        "  if (s!=0):\n",
        "    net.increment_classes(10)\n",
        "\n",
        "  net.cuda()\n",
        "  net.train(True)\n",
        "  p = net.parameters()\n",
        "  optimizer = optim.SGD(p, lr=0.02,weight_decay=0.00001,momentum=0.9) \n",
        "  scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [49,63], gamma=0.2)\n",
        "    \n",
        "  matrix = []\n",
        "  labe = []    \n",
        "  b_ac = 0\n",
        "\n",
        "  #### TRAIN ### \n",
        "  for epoch in range(0,NUM_EPOCHS):\n",
        "\n",
        "    running_corrects = 0 \n",
        "    total = 0\n",
        "\n",
        "    for indices, images, labels in train_loader:\n",
        "      images = Variable(images).cuda()\n",
        "      labels = Variable(labels).cuda()\n",
        "      indices = indices.cuda()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      g = net.forward(images.cuda())\n",
        "\n",
        "      _, preds = torch.max(g, 1)\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "      total += labels.size(0)\n",
        "\n",
        "      ##### LOSS #######\n",
        "      criterio= nn.CrossEntropyLoss()\n",
        "      g.cuda()\n",
        "\n",
        "      loss = criterio(g,labels)  \n",
        "        \n",
        "      ####################\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    accuracy = running_corrects / float(total)       \n",
        "    scheduler.step()\n",
        "    print ('Epoch [%d/%d], Loss: %.4f, Acc: %.2f' %(epoch+1, NUM_EPOCHS, loss.data, accuracy)) \n",
        "    \n",
        "    #### TEST ####\n",
        "    m=[]\n",
        "    l=[]\n",
        "    net.train(False)\n",
        "\n",
        "    total = 0.0\n",
        "    running_corrects = 0\n",
        "    for indices, images, labels in test_loader:\n",
        "        images = Variable(images).cuda()\n",
        "        out = net.forward(images)\n",
        "        _, preds = torch.max(out, 1)\n",
        "        running_corrects += torch.sum(preds.cpu() == labels.data).data.item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        m.extend(preds) \n",
        "        l.extend(labels)\n",
        "\n",
        "    matrix.append(m)\n",
        "    labe.append(l)     \n",
        "\n",
        "    accuracy = float(running_corrects / float(total))\n",
        "    print('Test Accuracy',accuracy)\n",
        "\n",
        "    if(b_ac < accuracy):\n",
        "      b_ac = accuracy \n",
        "\n",
        "  tot_matrix.append(matrix)\n",
        "  tot_labe.append(labe)\n",
        "  best_acc.append(b_ac)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoG5n001y5Fc",
        "colab_type": "text"
      },
      "source": [
        "**Confusion matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzf8XYP9sXVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np \n",
        "import matplotlib \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tacche = [10,20,30,40,50,60,70,80,90]\n",
        "\n",
        "x =  tot_matrix[9][69]\n",
        "l = tot_labe[9][69]\n",
        "\n",
        "l =[int(i) for i in l]\n",
        "x =[int(i) for i in x]\n",
        "\n",
        "cf = confusion_matrix(list(l),list(x))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15,15))\n",
        "im = ax.imshow(cf,cmap = 'plasma')\n",
        "\n",
        "ax.set_yticks(tacche)\n",
        "ax.set_xticks(tacche)\n",
        "\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
        "ax.set_title(\"image classification\")\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXX59VMDzQlT",
        "colab_type": "text"
      },
      "source": [
        "**Accuracy trend**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSkCMylUBBgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig,ax = plt.subplots(figsize=(15,10))\n",
        "ax.plot([10,20,30,40,50,60,70,80,90,100],best_acc,'k-o')\n",
        "plt.xlim(10,100)\n",
        "plt.ylim(0,1)\n",
        "plt.xlabel('Classes')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "print(best_acc)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}