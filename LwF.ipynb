{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LwF_jpynb.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armando-larocca/Project-IL-/blob/master/LwF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maPsZOgGkDot",
        "colab_type": "text"
      },
      "source": [
        "**Import utilities**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTYJwdP91lEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch.optim as optim \n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "DEVICE = torch.device('cuda:0')\n",
        "\n",
        "if not os.path.isdir('./Project-dir'):\n",
        "  !git clone https://github.com/armando-larocca/Project-IL-\n",
        "\n",
        "if not os.path.isdir('content/cifar100.py'):\n",
        "  !mv '/content/Project-IL-/cifar100.py' '/content'  \n",
        "  !mv '/content/Project-IL-/utils.py' '/content'  \n",
        "\n",
        "if not os.path.isdir('content/cifarResnet.py'):\n",
        "  !mv '/content/Project-IL-/cifarResnet.py' '/content'\n",
        "\n",
        "from cifarResnet import resnet32\n",
        "from cifar100 import *\n",
        "#from resnet import resnet18\n",
        "\n",
        "# Hyper Parameters\n",
        "num_epochs = 70\n",
        "batch_size = 128\n",
        "learning_rate = 2\n",
        "total_classes = 100\n",
        "num_classes = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upVUMZySkObo",
        "colab_type": "text"
      },
      "source": [
        "**LwF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9ORrBFe1uvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LwF(nn.Module):\n",
        "    def __init__(self,  n_classes):\n",
        "        \n",
        "        #### Network architecture #### \n",
        "        super(LwF, self).__init__()\n",
        "        self.feature_extractor = resnet32()\n",
        "        self.fc = nn.Linear(64, n_classes, bias=True)\n",
        "\n",
        "        self.n_classes = n_classes\n",
        "        self.n_known = 0\n",
        "       \n",
        "        self.p = self.parameters()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def increment_classes(self, n):\n",
        "      in_features = self.fc.in_features\n",
        "      out_features = self.fc.out_features\n",
        "      weight = self.fc.weight.data\n",
        "      bias = self.fc.bias.data\n",
        "\n",
        "      self.fc = nn.Linear(in_features, out_features+n, bias=True)\n",
        "      self.fc.weight.data[:out_features] = weight\n",
        "      self.fc.bias.data[:out_features] = bias\n",
        "      self.n_classes += n    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90whUB387UAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot(labels,n_cls):\n",
        "  hot = torch.zeros(len(labels), n_cls)\n",
        "  hot[range(hot.shape[0]), labels]=1\n",
        "  \n",
        "  return hot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzlq0yNqkTUR",
        "colab_type": "text"
      },
      "source": [
        "**Dataset preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNqI49pZ1uuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5071, 0.4867, 0.4408),std=(0.2675, 0.2565, 0.2761)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5071, 0.4867, 0.4408),std=(0.2675, 0.2565, 0.2761)),\n",
        "])\n",
        "\n",
        "\n",
        "shf = []\n",
        "for x in range(0,99):\n",
        "  shf.append(x)\n",
        "\n",
        "random.shuffle(shf)\n",
        "\n",
        "train_dataset = Cifar100(\".\\Data\", train=True, transform=transform)\n",
        "test_dataset = Cifar100(\".\\Data\", train=False, transform=transform_test)\n",
        "\n",
        "train_dataset._shuffle_(shf)\n",
        "test_dataset._shuffle_(shf)\n",
        "\n",
        "incr_train = train_dataset.__incremental_train_indexes__(1)\n",
        "incr_val = test_dataset.__incremental_val_indexes__(0)\n",
        "\n",
        "decine_train = []\n",
        "decine_val = []\n",
        "\n",
        "for i in range(0,10):\n",
        "  val_dataset = Subset(test_dataset, incr_val[i])\n",
        "  training_dataset = Subset(train_dataset, incr_train[i])\n",
        "  decine_train.append(training_dataset)\n",
        "  decine_val.append(val_dataset) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLTsEtmpkZxG",
        "colab_type": "text"
      },
      "source": [
        "**Main**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-dKgHvT4smg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = LwF(10)\n",
        "\n",
        "best_acc = []\n",
        "tot_matrix = []\n",
        "tot_labe = []\n",
        "\n",
        "for s in range(0,10):\n",
        "\n",
        "  net.cuda()\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(decine_train[int(s)], batch_size=batch_size,shuffle=True, num_workers=4)\n",
        "  test_loader = torch.utils.data.DataLoader(decine_val[int(s)], batch_size=batch_size,shuffle=True, num_workers=4)\n",
        "\n",
        "  print(len(train_loader))\n",
        "  print(len(test_loader))\n",
        "\n",
        "  #### OLD OUTPUT ### \n",
        "  q = torch.zeros(50000, net.n_classes).cuda()\n",
        "  for  indices, images, labels in train_loader:\n",
        "    images = Variable(images).cuda()\n",
        "    indices = indices.cuda()\n",
        "    old_out = net.forward(images.cuda())\n",
        "    q[indices] = old_out.data\n",
        "    \n",
        "  q = Variable(q).cuda()\n",
        "  \n",
        "  if(s!=0):\n",
        "    net.increment_classes(10)\n",
        "\n",
        "  net.cuda()\n",
        "  net.train(True)\n",
        "  p = net.parameters()\n",
        "  optimizer = optim.SGD(p, lr=2.0,weight_decay=0.00001,momentum=0.9) \n",
        "  scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [49,63], gamma=0.2)\n",
        "    \n",
        "  matrix = []\n",
        "  labe = []    \n",
        "  b_ac = 0\n",
        "\n",
        "  #### TRAIN ### \n",
        "  for epoch in range(0,num_epochs):\n",
        "\n",
        "    running_corrects = 0 \n",
        "    total = 0\n",
        "\n",
        "    for indices, images, labels in train_loader:\n",
        "      images = Variable(images).cuda()\n",
        "      labels = Variable(labels).cuda()\n",
        "      indices = indices.cuda()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      g = net.forward(images.cuda())\n",
        "\n",
        "      _, preds = torch.max(g, 1)\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "      total += labels.size(0)\n",
        "\n",
        "      ##### LOSS #######\n",
        "      q_i = q[indices]\n",
        "      one_hot_batch = one_hot(labels,net.n_classes)\n",
        "      sigmoid = nn.Sigmoid()\n",
        "      criterio=nn.BCEWithLogitsLoss() \n",
        "      criterio1= nn.CrossEntropyLoss()\n",
        "      criterio \n",
        "      q_i.cuda()\n",
        "      g.cuda()\n",
        "\n",
        "      if(net.n_classes==10):\n",
        "        loss = criterio(g, one_hot_batch.cuda())  \n",
        "      else: \n",
        "        x1 = q_i[:,:net.n_classes-10]\n",
        "        x2 = one_hot_batch[: ,net.n_classes-10 :net.n_classes]            \n",
        "        target = torch.cat( (sigmoid(x1), x2.cuda()) , 1)\n",
        "        loss = criterio(g, target)\n",
        "        \n",
        "      ####################\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    accuracy = running_corrects / float(total)       \n",
        "    scheduler.step()\n",
        "    print ('Epoch [%d/%d], Loss: %.4f, Acc: %.2f' %(epoch+1, num_epochs, loss.data, accuracy)) \n",
        "    \n",
        "    #### TEST ####\n",
        "    m=[]\n",
        "    l=[]\n",
        "    net.train(False)\n",
        "\n",
        "    total = 0.0\n",
        "    running_corrects = 0\n",
        "    for indices, images, labels in test_loader:\n",
        "        images = Variable(images).cuda()\n",
        "        out = net.forward(images)\n",
        "        _, preds = torch.max(out, 1)\n",
        "        running_corrects += torch.sum(preds.cpu() == labels.data).data.item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        m.extend(preds) \n",
        "        l.extend(labels)\n",
        "\n",
        "    matrix.append(m)\n",
        "    labe.append(l)     \n",
        "\n",
        "    accuracy = float(running_corrects / float(total))\n",
        "    print('Test Accuracy',accuracy)\n",
        "\n",
        "    if(b_ac < accuracy):\n",
        "      b_ac = accuracy \n",
        "\n",
        "  tot_matrix.append(matrix)\n",
        "  tot_labe.append(labe)\n",
        "  best_acc.append(b_ac)         "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPiYYD5Gkk4r",
        "colab_type": "text"
      },
      "source": [
        "**Confusion matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAeO7Kb_W2Wj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np \n",
        "import matplotlib \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tacche = [10,20,30,40,50,60,70,80,90]\n",
        "\n",
        "x =  tot_matrix[0][0]\n",
        "l = tot_labe[0][0]\n",
        "\n",
        "l =[int(i) for i in l]\n",
        "x =[int(i) for i in x]\n",
        "\n",
        "cf = confusion_matrix(list(l),list(x))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15,15))\n",
        "im = ax.imshow(cf,cmap = 'plasma')\n",
        "\n",
        "ax.set_yticks(tacche)\n",
        "ax.set_xticks(tacche)\n",
        "\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
        "ax.set_title(\"image classification\")\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCDG9HY_kna7",
        "colab_type": "text"
      },
      "source": [
        "**Accuracy plot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqNufSEAmLSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig,ax = plt.subplots(figsize=(15,10))\n",
        "ax.plot([10,20,30,40,50,60,70,80,90,100],best_acc,'k-o')\n",
        "plt.xlim(10,100)\n",
        "plt.ylim(0,1)\n",
        "plt.xlabel('Classes')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "print(best_acc)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}